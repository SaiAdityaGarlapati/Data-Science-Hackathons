{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification demo including training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation, Dropout\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "## Convolution(64 feature detector of dimension 3 by 3), input shape 3 layer for color image)\n",
    "classifier.add(Convolution2D(64,3,3,input_shape = (64,64,3), activation = 'relu'))\n",
    "## MaxPooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Convolution2D(64,3,3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Convolution2D(64,3,3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Aditya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Fully connected ANN, Hidden ANN and output layer\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 64, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compliling\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data importing and transforming and scaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6206 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importing training data\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                               target_size=(64, 64),\n",
    "                                               batch_size=6,\n",
    "                                               class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "#which is cat which is dog?\n",
    "label_map = (train_set.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importng test data\n",
    "test_set = test_datagen.flow_from_directory('images_test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=6,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3103/3103 [==============================] - 151s 49ms/step - loss: 0.5276 - acc: 0.7351\n",
      "Epoch 2/10\n",
      "3103/3103 [==============================] - 144s 46ms/step - loss: 0.4235 - acc: 0.8073- ETA: 2s\n",
      "Epoch 3/10\n",
      "3103/3103 [==============================] - 141s 46ms/step - loss: 0.3792 - acc: 0.8311\n",
      "Epoch 4/10\n",
      "3103/3103 [==============================] - 142s 46ms/step - loss: 0.3368 - acc: 0.8550\n",
      "Epoch 5/10\n",
      "3103/3103 [==============================] - 140s 45ms/step - loss: 0.3066 - acc: 0.8681\n",
      "Epoch 6/10\n",
      "3103/3103 [==============================] - 141s 45ms/step - loss: 0.2737 - acc: 0.8828\n",
      "Epoch 7/10\n",
      "3103/3103 [==============================] - 144s 47ms/step - loss: 0.2432 - acc: 0.89970s - loss: 0.2427 - \n",
      "Epoch 8/10\n",
      "3103/3103 [==============================] - 144s 46ms/step - loss: 0.2218 - acc: 0.9066\n",
      "Epoch 9/10\n",
      "3103/3103 [==============================] - 154s 50ms/step - loss: 0.1961 - acc: 0.9200\n",
      "Epoch 10/10\n",
      "3103/3103 [==============================] - 142s 46ms/step - loss: 0.1775 - acc: 0.9295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b348575e48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting model to images\n",
    "classifier.fit_generator(train_set,steps_per_epoch=3103,epochs=10,validation_data=test_set,validation_steps=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction of single new data\n",
    "\n",
    "test_image= image.load_img('img_0107.jpg'\n",
    "                           ,target_size =(64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1B348575E10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert image to array\n",
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single prediction change the dimension using axis. To remove problem of batch\n",
    "test_image = np.expand_dims(test_image,axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class of dog and cat\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# saving cat dog classification model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictor function for reusability\n",
    "def class_predictor(img_name):\n",
    "    test_image= image.load_img('images_test/'+img_name+'.jpg'\n",
    "                           ,target_size =(64,64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image,axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "for i in test['id']:\n",
    "    l.append(class_predictor(str(i)))\n",
    "\n",
    "test['class_prediction'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0966</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_6542</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_2360</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0763</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_6579</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id class_prediction\n",
       "0  img_0966              dog\n",
       "1  img_6542              dog\n",
       "2  img_2360              dog\n",
       "3  img_0763              cat\n",
       "4  img_6579              dog"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat breed classification cat_model\n",
    "cat_model = Sequential()\n",
    "cat_model.add(Conv2D(64, (3, 3), input_shape=(64,64,3)))\n",
    "cat_model.add(Activation('relu'))\n",
    "cat_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cat_model.add(Conv2D(64, (3, 3)))\n",
    "cat_model.add(Activation('relu'))\n",
    "cat_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cat_model.add(Conv2D(64, (3, 3)))\n",
    "cat_model.add(Activation('relu'))\n",
    "cat_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#fully connected layers\n",
    "cat_model.add(Flatten())  \n",
    "cat_model.add(Dense(64))\n",
    "cat_model.add(Activation('relu'))\n",
    "cat_model.add(Dropout(0.2))\n",
    "cat_model.add(Dense(5))\n",
    "cat_model.add(Activation('softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling cat breed model\n",
    "cat_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2968 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_cat_breed/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'images_test/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3103/3103 [==============================] - 357s 115ms/step - loss: 0.9857 - acc: 0.6001\n",
      "Epoch 2/10\n",
      "3103/3103 [==============================] - 358s 116ms/step - loss: 0.6672 - acc: 0.7354\n",
      "Epoch 3/10\n",
      "3103/3103 [==============================] - 363s 117ms/step - loss: 0.4575 - acc: 0.8216\n",
      "Epoch 4/10\n",
      "3103/3103 [==============================] - 360s 116ms/step - loss: 0.3428 - acc: 0.8651\n",
      "Epoch 5/10\n",
      "3103/3103 [==============================] - 363s 117ms/step - loss: 0.2808 - acc: 0.8935\n",
      "Epoch 6/10\n",
      "3103/3103 [==============================] - 367s 118ms/step - loss: 0.2372 - acc: 0.9109\n",
      "Epoch 7/10\n",
      "3103/3103 [==============================] - 360s 116ms/step - loss: 0.2114 - acc: 0.9219\n",
      "Epoch 8/10\n",
      "3103/3103 [==============================] - 359s 116ms/step - loss: 0.1918 - acc: 0.9282\n",
      "Epoch 9/10\n",
      "3103/3103 [==============================] - 358s 115ms/step - loss: 0.1804 - acc: 0.9334\n",
      "Epoch 10/10\n",
      "3103/3103 [==============================] - 360s 116ms/step - loss: 0.1619 - acc: 0.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b34cd1d908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_samples =6206\n",
    "nb_validation_samples = 1096\n",
    "cat_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3103,\n",
    "        validation_steps=108,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# saving cat dog classification model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = cat_model.to_json()\n",
    "with open(\"cat_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cat_model.save_weights(\"cat_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#,\"DOG 21\",\"DOG 22\",\"DOG 23\",\"DOG 24\",\"DOG 25\"\n",
    "labels=[\"CAT 11\",\"CAT 12\",\"CAT 13\",\"CAT 14\",\"CAT 15\"]\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.index('CAT 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_prediction</th>\n",
       "      <th>cat_breed_predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0966</td>\n",
       "      <td>dog</td>\n",
       "      <td>CAT 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_6542</td>\n",
       "      <td>dog</td>\n",
       "      <td>CAT 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_2360</td>\n",
       "      <td>dog</td>\n",
       "      <td>CAT 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0763</td>\n",
       "      <td>cat</td>\n",
       "      <td>CAT 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_6579</td>\n",
       "      <td>dog</td>\n",
       "      <td>CAT 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id class_prediction cat_breed_predictor\n",
       "0  img_0966              dog              CAT 13\n",
       "1  img_6542              dog              CAT 14\n",
       "2  img_2360              dog              CAT 11\n",
       "3  img_0763              cat              CAT 12\n",
       "4  img_6579              dog              CAT 12"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_breed_predictor(img_name):\n",
    "    test_image= image.load_img('images_test/'+img_name+'.jpg'\n",
    "                           ,target_size =(64,64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    ## For single prediction change the dimension using axis. To remove problem of batch\n",
    "    test_image = np.expand_dims(test_image,axis = 0)\n",
    "    result = cat_model.predict(test_image)\n",
    "    for i in range(len(result[0])):\n",
    "        if result[0][i]==1:\n",
    "            return labels[i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "for i,j in zip(test['id'],test['class_prediction']):\n",
    "    if j =='cat':\n",
    "        l.append(cat_breed_predictor(str(i)))\n",
    "    else:\n",
    "        l.append(\"\")\n",
    "    \n",
    "\n",
    "test['cat_breed_predictor'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('Submission-Work-in-progress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dog breed prediction\n",
    "# Cat breed classification dog_model\n",
    "dog_model = Sequential()\n",
    "dog_model.add(Conv2D(64, (3, 3), input_shape=(64,64,3)))\n",
    "dog_model.add(Activation('relu'))\n",
    "dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "dog_model.add(Conv2D(64, (3, 3)))\n",
    "dog_model.add(Activation('relu'))\n",
    "dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "dog_model.add(Conv2D(64, (3, 3)))\n",
    "dog_model.add(Activation('relu'))\n",
    "dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#fully connected layers\n",
    "dog_model.add(Flatten())  \n",
    "dog_model.add(Dense(64))\n",
    "dog_model.add(Activation('relu'))\n",
    "dog_model.add(Dropout(0.2))\n",
    "dog_model.add(Dense(5))\n",
    "dog_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3238 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_dog_breed/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'images_test/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3103/3103 [==============================] - 377s 121ms/step - loss: 1.0792 - acc: 0.5674\n",
      "Epoch 2/10\n",
      "3103/3103 [==============================] - 371s 119ms/step - loss: 0.6010 - acc: 0.7702\n",
      "Epoch 3/10\n",
      "3103/3103 [==============================] - 387s 125ms/step - loss: 0.3776 - acc: 0.8560\n",
      "Epoch 4/10\n",
      "3103/3103 [==============================] - 424s 137ms/step - loss: 0.2821 - acc: 0.8945\n",
      "Epoch 5/10\n",
      "3103/3103 [==============================] - 381s 123ms/step - loss: 0.2284 - acc: 0.9175\n",
      "Epoch 6/10\n",
      "3103/3103 [==============================] - 376s 121ms/step - loss: 0.2021 - acc: 0.9288\n",
      "Epoch 7/10\n",
      "3103/3103 [==============================] - 376s 121ms/step - loss: 0.1881 - acc: 0.9328\n",
      "Epoch 8/10\n",
      "3103/3103 [==============================] - 361s 116ms/step - loss: 0.1651 - acc: 0.9422\n",
      "Epoch 9/10\n",
      "3103/3103 [==============================] - 360s 116ms/step - loss: 0.1538 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "3103/3103 [==============================] - 370s 119ms/step - loss: 0.1459 - acc: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b350ccdf60>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_samples =6206\n",
    "nb_validation_samples = 1096\n",
    "dog_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3103,\n",
    "        validation_steps=108,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = dog_model.to_json()\n",
    "with open(\"dog_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "dog_model.save_weights(\"dog_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"DOG 21\",\"DOG 22\",\"DOG 23\",\"DOG 24\",\"DOG 25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_breed_predictor(img_name):\n",
    "    test_image= image.load_img('images_test/'+img_name+'.jpg'\n",
    "                           ,target_size =(64,64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    ## For single prediction change the dimension using axis. To remove problem of batch\n",
    "    test_image = np.expand_dims(test_image,axis = 0)\n",
    "    result = cat_model.predict(test_image)\n",
    "    for i in range(len(result[0])):\n",
    "        if result[0][i]==1:\n",
    "            return labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "for i,j in zip(test['id'],test['class_prediction']):\n",
    "    if j =='dog':\n",
    "        l.append(dog_breed_predictor(str(i)))\n",
    "    else:\n",
    "        l.append(\"\")\n",
    "    \n",
    "\n",
    "test['dog_breed_predictor'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('Submission-Work-in-progress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"final prediction\"] = test.cat_breed_predictor.str.cat(test.dog_breed_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =pd.read_csv(\"Submission final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[]\n",
    "for i in submission['class_prediction']:\n",
    "    if i == 'dog':\n",
    "        l.append(2)\n",
    "    else:\n",
    "        l.append(1)\n",
    "\n",
    "submission['class'] = l\n",
    "\n",
    "submission.to_csv('Submission final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
